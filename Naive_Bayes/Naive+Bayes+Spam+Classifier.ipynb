{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Spam Filter for SMS messages with Naive Bayes\n",
    "\n",
    "In this short notebook, we are going to describe the [Naive Bayes algorithm](https://en.wikipedia.org/wiki/Naive_Bayes_classifier) and how it can be used to build a rudimentary spam classifier for SMS messages.\n",
    "\n",
    "Our goal is to create a classifier that when fed an SMS message determines whether the message is spam or not. To accomplish this we'll try to compute the conditional probability that a message is spam given its contents,\n",
    "\n",
    "$$P(spam|message)$$\n",
    "\n",
    "We can apply [Bayes theorem](https://en.wikipedia.org/wiki/Bayes%27_theorem) to help us out here. Bayes theorem says that \n",
    "\n",
    "$$P(spam|message)=\\frac{P(message|spam)\\cdot P(spam)}{P(message)}$$\n",
    "\n",
    "Since every message is classified as either spam or not (which we'll label 'ham'), spam and ham are complementary events, i.e. $Ham\\ =\\ Spam^C$. Thus, $P(ham|message)=1-P(spam|message)$.\n",
    "\n",
    "The Naive Bayes algorithm estimates the probabilities $P(ham|message)$ and $P(spam|message)$ with some convenient (i.e. naive) conditions and then classifies the message based on which probability is greater. We'll discuss the details later. At the end of the notebook we'll evaluate our model using the `sklearn.metrics` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "    <ul>\n",
    "        <li>Reading and Cleaning Data</li>\n",
    "        <li>The Naive Bayes Classifier</li>\n",
    "        <ul><li>Additive Smoothing</li></ul>\n",
    "        <li>Building The Model</li>\n",
    "        <li>Prediction and Evaluation</li>\n",
    "        <ul><li>Binary Classification Evaluation Metrics</li><ul>\n",
    "    </ul>\n",
    "\n",
    "</div>\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Cleaning the Data\n",
    "\n",
    "Now lets read in the data as a Pandas Dataframe and clean it up a bit. The dataset was put together by Tiago A. Almeida and José María Gómez Hidalgo, and it can be downloaded from the The [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection). You can also download the dataset directly from this [link](https://dq-content.s3.amazonaws.com/433/SMSSpamCollection). The data collection process is described in more details on this [page](http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/#composition), where you can also find some of the authors' papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#read in tab-seperated file and name the columns \"Label\" and \"SMS\"\n",
    "import pandas as pd\n",
    "messages=pd.read_csv('SMSSpamCollection.txt',sep='\\t',header=None,names=['Labels','SMS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Labels                                                SMS\n",
      "0    ham  Go until jurong point, crazy.. Available only ...\n",
      "1    ham                      Ok lar... Joking wif u oni...\n",
      "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3    ham  U dun say so early hor... U c already then say...\n",
      "4    ham  Nah I don't think he goes to usf, he lives aro...\n",
      "(5572, 2)\n"
     ]
    }
   ],
   "source": [
    "print(messages.head())\n",
    "\n",
    "print(messages.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the dataframe has two columns, the plain text of the SMS message and the predetermined labeling 'Ham' for a non spam message and 'Spam' otherwise. Let's see the breakdown of messages classified as spam or not spam (i.e. ham)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: Labels, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['Labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: Labels, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['Labels'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that about 87% of the messages are not spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to build our spam filter we are going to split our labeled data in training and test sets by an 80-20 split. We will build our model based on the training set and then treat the test set as new messages to test our model against. We can then compare the label generated by our model to the original label.\n",
    "\n",
    "We'll start by randomizing our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# The sample method on a datframe with parameter frac=1 gives us a permutation of our dataset. \n",
    "# Setting the random state allows us to reproduce our results.\n",
    "\n",
    "messages_random=messages.sample(frac=1,random_state=1)\n",
    "\n",
    "training_test_index = round(len(messages_random) * 0.8)\n",
    "\n",
    "# We'll take the first 20% of entries as our training set, and the remaining as our test set.\n",
    "\n",
    "training_set=messages_random.iloc[:training_test_index,:].reset_index(drop=True)\n",
    "test_set=messages_random.iloc[training_test_index:,:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     0.86541\n",
      "spam    0.13459\n",
      "Name: Labels, dtype: float64\n",
      "ham     0.868043\n",
      "spam    0.131957\n",
      "Name: Labels, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(training_set['Labels'].value_counts(normalize=True))\n",
    "print(test_set['Labels'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentages looking good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply the Naive Bayes  algorithm we want to count the number of unique words that appear throughout all SMS messages and count how often each word appears in each message. To make the data a bit cleaner for our model we are going to strip all punctuation from each entry in the `SMS` column of the `training_set` data frame and reduce all resulting strings to lower-case only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth   there s a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Labels                                                SMS\n",
       "0    ham                       yep  by the pretty sculpture\n",
       "1    ham      yes  princess  are you going to make me moan \n",
       "2    ham                         welp apparently he retired\n",
       "3    ham                                            havent \n",
       "4    ham  i forgot 2 ask ü all smth   there s a card on ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set['SMS']=training_set['SMS'].str.replace('\\W',' ').str.lower()\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll collect all the unique word present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "vocabulary=[]\n",
    "# Change the 'SMS' column from a string to a list of all the words present in each message\n",
    "training_set['SMS']=training_set['SMS'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all unique words in the messages\n",
    "for text in training_set['SMS']:\n",
    "    for word in text:\n",
    "        if word not in vocabulary:\n",
    "            vocabulary.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the list `vocabulary` contains all the unique words that appeared in the training set SMS messages. Now we'll create a disctionary whose keys are each word in `vocabulary` and whose values are lists keeping track of how often the given word occurs in each message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a dictionary where each word is a key and the value is a list.\n",
    "# the list contains the number of times each word appears in each message by index.\n",
    "word_counts_per_sms={word:[0]*len(training_set['SMS']) for word in vocabulary}\n",
    "for index, sms in enumerate(training_set['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>SMS</th>\n",
       "      <th>yep</th>\n",
       "      <th>by</th>\n",
       "      <th>the</th>\n",
       "      <th>pretty</th>\n",
       "      <th>sculpture</th>\n",
       "      <th>yes</th>\n",
       "      <th>princess</th>\n",
       "      <th>are</th>\n",
       "      <th>...</th>\n",
       "      <th>beauty</th>\n",
       "      <th>hides</th>\n",
       "      <th>secrets</th>\n",
       "      <th>n8</th>\n",
       "      <th>jewelry</th>\n",
       "      <th>related</th>\n",
       "      <th>trade</th>\n",
       "      <th>arul</th>\n",
       "      <th>bx526</th>\n",
       "      <th>wherre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Labels                                                SMS  yep  by  the  \\\n",
       "0    ham                  [yep, by, the, pretty, sculpture]    1   1    1   \n",
       "1    ham  [yes, princess, are, you, going, to, make, me,...    0   0    0   \n",
       "2    ham                    [welp, apparently, he, retired]    0   0    0   \n",
       "3    ham                                           [havent]    0   0    0   \n",
       "4    ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...    0   0    0   \n",
       "\n",
       "   pretty  sculpture  yes  princess  are  ...  beauty  hides  secrets  n8  \\\n",
       "0       1          1    0         0    0  ...       0      0        0   0   \n",
       "1       0          0    1         1    1  ...       0      0        0   0   \n",
       "2       0          0    0         0    0  ...       0      0        0   0   \n",
       "3       0          0    0         0    0  ...       0      0        0   0   \n",
       "4       0          0    0         0    0  ...       0      0        0   0   \n",
       "\n",
       "   jewelry  related  trade  arul  bx526  wherre  \n",
       "0        0        0      0     0      0       0  \n",
       "1        0        0      0     0      0       0  \n",
       "2        0        0      0     0      0       0  \n",
       "3        0        0      0     0      0       0  \n",
       "4        0        0      0     0      0       0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert the above dictionary to a dataframe and concatenate with the original data frame.\n",
    "word_counts=pd.DataFrame(word_counts_per_sms)\n",
    "training_set_clean=pd.concat([training_set,word_counts],axis=1)\n",
    "training_set_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above dataframe now contains the label for each message and a column for every unique word with the number of times the given word appeared in that message. We can now compute the parameters necessary to apply the Naive Bayes classification algorithm. But what is Naive Bayes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Naive Bayes Classifier\n",
    "\n",
    "First note that \n",
    "\n",
    "$$P(spam|message)=\\frac{P(message|spam)\\cdot P(spam)}{P(message)},\\ \\ \\ \\ P(ham|message)=\\frac{P(message|ham)\\cdot P(ham)}{P(message)}$$\n",
    "\n",
    "have the same denominator, so we really need only to compute $P(message|spam)\\cdot P(spam)$ and $P(message|ham)\\cdot P(ham)$ and compare their relative size. \n",
    "\n",
    "$P(spam)$ is easy to compute; we need only look at the percentage of total messages already classified as spam. In the training set, spam messages account for 86.541% of the total. But what about $P(message|spam)$? This is asking what is the probability that a given message occured knowing that it's spam a priori. Let's look at a message with one word first to illustrate.\n",
    "\n",
    "Say we recieve the message \"winner\". To compute $P('winner'|spam)$ we just looka t how many times the word 'winner' occurs in all spam messages and divide by the total number of words in all spam messages. So,\n",
    "\n",
    "$$P(spam|'winner')\\propto\\ P(spam)\\cdot P('winner'|spam)=\\frac{\\#\\ of\\ spam\\ messages}{\\#\\ of\\ total\\ messages}\\cdot\\frac{\\#\\ of\\ times\\ winner\\ occurs\\ in\\ spam\\ messages}{\\#\\ of\\ words\\ in\\ spam\\ messages}$$\n",
    "\n",
    "So now we can compute $P(word|spam)$ for a given word and we just interpret a message as the event $w_1w_2...w_n$, where $w_i$ is the $i^{th}$ word in the message. Then by Bayes theorem we have,\n",
    "\n",
    "$$P(spam|w_1w_2...w_n)\\propto\\ P(spam)\\cdot P(w_1w_2...w_n|spam)$$\n",
    "\n",
    "Now comes the 'naive' in Naive Bayes. For one, in this instantiation we've already gotten rid of all punctuation and capitalization even though spam messages may contain more grammatical errors. Furthermore, we are going to make a massive assumption that any pair of words $w_i,\\ w_j$ are conditionally independent, i.e. $P(w_iw_j|spam)=P(w_i|spam)\\cdot P(w_j|spam)$. This is clearly naive! Words in real messages are often in a relationship of dependence. For example, the words 'winner' and 'money' often appear in the same message.\n",
    "\n",
    "With the above assumptions we can compute\n",
    "\n",
    "$$P(spam|w_1w_2...w_n)\\propto\\ P(spam)\\cdot P(w_1|spam)\\cdot P(w_2|spam)\\cdot...\\cdot P(w_n|spam)\\ =\\ P(spam)\\prod_{i=1}^{n} P(w_i)$$\n",
    "\n",
    "### Additive Smoothing\n",
    "\n",
    "There is one last caveat to consider before we code up the classifier. If we have words in a new message that only appear in one category or not at all, sometimes both $P(spam|message)$ and $P(spam^C|message)$ can evaluate to zero due to the assumed indepence conditions. To make it so none of the probabilities evaluate to zero we'll use a technique called [additive smoothing](https://en.wikipedia.org/wiki/Additive_smoothing). With the smoothing adjustment $P(w_i|Spam)$ and $P(w_i|Ham)$ take the following forms,\n",
    "$$P(w_i|Spam)\\ =\\ \\frac{N_{w_i|Spam}+\\alpha}{N_{Spam}+\\alpha\\cdot N_{Vocabulary}}$$\n",
    "$$P(w_i|Ham)\\ =\\ \\frac{N_{w_i|Ham}+\\alpha}{N_{Ham}+\\alpha\\cdot N_{Vocabulary}},$$\n",
    "\n",
    "where $N_{Vocabulary}$ is the number of *unique* words appearing in all training messages. When α=1, the additive smoothing technique is most commonly known as Laplace smoothing (or add-one smoothing). However, it is also possible to use α<1, in which case the technique is called Lidstone smoothing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n",
    "Now we'll compute the parameters we need to apply the Naive Bayes algorithm with Laplace smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Laplace smoothing constant\n",
    "alpha=1\n",
    "\n",
    "# Computing P(ham) and P(spam)\n",
    "p_ham_tr=training_set['Labels'].value_counts(normalize=True)['ham']\n",
    "p_spam_tr=training_set['Labels'].value_counts(normalize=True)['spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Seperating train messages into ham and spam\n",
    "spam_messages = training_set_clean[training_set_clean['Labels'] == 'spam']\n",
    "ham_messages = training_set_clean[training_set_clean['Labels'] == 'ham']\n",
    "\n",
    "# Computing n_spam and n_ham, the total number of words in spam and ham messages respectively\n",
    "num_words_per_spam=spam_messages['SMS'].apply(len)\n",
    "n_spam=num_words_per_spam.sum()\n",
    "\n",
    "num_words_per_ham=ham_messages['SMS'].apply(len)\n",
    "n_ham=num_words_per_ham.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# instantiating dictionaries that will contain {word:P(sord|spam)} and {word:P(word:ham)}\n",
    "parameters_spam={unique_word:0 for unique_word in vocabulary}\n",
    "parameters_ham={unique_word:0 for unique_word in vocabulary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the    157\n",
       "of      79\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create series counting the number of times each word appears in spam and ham messages\n",
    "spam_words=spam_messages.sum()\n",
    "ham_words=ham_messages.sum()\n",
    "spam_words[['the','of']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Use the additive smoothing formulas above to compute P(w_i|spam) and P(w_i|ham) for every unique word\n",
    "# Adjust the dictionaries parameters_spam and parameters_ham accordingly\n",
    "\n",
    "n_v=len(vocabulary)\n",
    "denominator_spam=n_spam+alpha*n_v\n",
    "denominator_ham=n_ham+alpha*n_v\n",
    "for word in vocabulary:\n",
    "    numerator_spam=spam_words[word]+alpha\n",
    "    parameters_spam[word]=numerator_spam/denominator_spam\n",
    "    \n",
    "    numerator_ham=ham_words[word]+alpha\n",
    "    parameters_ham[word]=numerator_ham/denominator_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.013395878191325745, 0.013407043050537588)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(parameters_ham['a'],parameters_spam['a'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have computed\n",
    "\n",
    "$$P(w_i|spam)\\ and\\ P(w_i|spam)$$\n",
    "\n",
    "for each word in vocabulary set we can estimate the relative sizes of \n",
    "\n",
    "$$P(spam|new\\ message)\\ and\\ P(ham|new\\ message),$$\n",
    "\n",
    "and the classify the new message according to which is larger!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import regular expression library\n",
    "import re\n",
    "\n",
    "'''\n",
    "naive_bayes will take a new message string and use the above described naive bayes algorithm\n",
    "to classify the message as either spam or ham\n",
    "'''\n",
    "\n",
    "def naive_bayes(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    \n",
    "\n",
    "    p_spam_given_message = p_spam_tr\n",
    "    p_ham_given_message = p_ham_tr\n",
    "      \n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word]\n",
    "        \n",
    "        \n",
    "\n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the classifier does for the following messages which to the human eye seem to clearly be not spam and spam respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Later i guess. I needa do mcat study too.\n",
      "\n",
      "Text & meet someone sexy today. U can find a date or even flirt its up to U. Join 4 just 10p. REPLY with NAME & AGE eg Sam 25. 18 -msg recd@thirtyeight pence\n"
     ]
    }
   ],
   "source": [
    "print(test_set['SMS'][0]+'\\n')\n",
    "print(test_set['SMS'][1112])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 3.4831070937898343e-26\n",
      "P(Ham|message): 4.253245130534654e-19\n",
      "Label: Ham\n",
      "\n",
      "\n",
      "P(Spam|message): 2.6405759833376274e-98\n",
      "P(Ham|message): 2.5002378335495614e-106\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "naive_bayes(test_set['SMS'][0])\n",
    "print('\\n')\n",
    "naive_bayes(test_set['SMS'][1112])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets change the above function a bit so it returns the classification label rather than just printing it. If the estimated values are equal, $P(spam|message)=P(ham|message)$ then the classifier informs us that we need to take a look ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_classifier(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    \n",
    "\n",
    "    p_spam_given_message = n_spam\n",
    "    p_ham_given_message = n_ham\n",
    "      \n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word]\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'requires human classification'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and Evaluation\n",
    "\n",
    "We can now apply our classifier to the test set as a whole. We will add a `predicted` colum to the `test_set` dataframe. We'll then also add a Boolean column `correct` to keep track of whether or not the classifier chose the correct label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['predicted']=test_set['SMS'].apply(naive_bayes_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Labels                                                SMS predicted\n",
       "0    ham          Later i guess. I needa do mcat study too.       ham\n",
       "1    ham             But i haf enuff space got like 4 mb...       ham\n",
       "2   spam  Had your mobile 10 mths? Update to latest Oran...      spam\n",
       "3    ham  All sounds good. Fingers . Makes it difficult ...       ham\n",
       "4    ham  All done, all handed in. Don't know if mega sh...       ham"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham                              968\n",
       "spam                             145\n",
       "requires human classification      1\n",
       "Name: predicted, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['predicted'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that the classifier wasn't able to classify one of the messages so we'll have to do it ourselves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293    A Boy loved a gal. He propsd bt she didnt mind...\n",
       "Name: SMS, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[test_set['predicted']=='requires human classification']['SMS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difficult to say! Given the romantic nature and mispelled words I think I would personally see it as spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     968\n",
       "spam    146\n",
       "Name: predicted, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.loc[293,'predicted']='spam'\n",
    "test_set['predicted'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now every message is classified. We'll also add a Boolean `correct` coulmn to see if our prediction matches with the label from the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['correct']=(test_set['Labels']==test_set['predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Labels                                                SMS predicted  correct\n",
       "0    ham          Later i guess. I needa do mcat study too.       ham     True\n",
       "1    ham             But i haf enuff space got like 4 mb...       ham     True\n",
       "2   spam  Had your mobile 10 mths? Update to latest Oran...      spam     True\n",
       "3    ham  All sounds good. Fingers . Makes it difficult ...       ham     True\n",
       "4    ham  All done, all handed in. Don't know if mega sh...       ham     True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at some accuracy metrics to evaluate our model!\n",
    "\n",
    "### Binary Classification Evaluation Metrics\n",
    "\n",
    "To wrap things up we'll discuss some metrics for evaluating binary classifiers.\n",
    "\n",
    "A stright forward metric is prediction accuracy. We simply want to know how many predictions did we get correct.\n",
    "\n",
    "$$Prediction\\ Accuracy\\ =\\ \\frac{Number\\ of\\ Correct\\ Predictions}{Number\\ of\\ Total\\ Predictions}$$\n",
    "\n",
    "We also want to look at precision and recall, also know as the true positive and true negative rates respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9865350089766607"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_set['Labels'],test_set['predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our model classified about 98% of the messages correctly. Accuracy alone doesn't discriminate between the different types of binary classifications. Since we're trying to find spam messages, we'll take a spam classification as 'positive' and ham as 'negative. Then there are 4 kinds of binary classifications detailed in the table below,\n",
    "\n",
    "|Prediction|Observation|            |\n",
    "|----------|-----------|------------|\n",
    "|          |Spam      |Ham  |\n",
    "|Spam     |True Positive (TP)|False Positive (FP)|\n",
    "|Ham       |False Negative (FM)|True Negative (TN)|\n",
    "\n",
    "There are some binary classification measures that are more subtle than accuracy alone. For example, we could look at **sensitivity**, or the true positive rate,\n",
    "\n",
    "$$Sensitivity\\ =\\ \\frac{True\\ Positives}{True\\ Positives\\ +\\ False\\ Negatives}.$$\n",
    "\n",
    "Of all the messages that should have been classified as spam, how many were correctly labeled as such. Sensitivity is also known as **recall**. Then we also  have **specificity**, or the true negative rate,\n",
    "\n",
    "$$Specificity\\ =\\ \\frac{True\\ Negatives}{True\\ Negatives\\ +\\ False\\ Positives}$$\n",
    "\n",
    "Of all the messages that should have gotten through our filter (i.e. ham), what percentage did make it to pur inbox. We also have **precision**,\n",
    "\n",
    "$$Precision\\ =\\ \\frac{True\\ Positives}{True\\ Positives\\ +\\ False\\ Positives},$$\n",
    "\n",
    "which measures how many of the spam predictions were relevant. Different models may purposely try to maximize sensitivity relative to recall or vice-versa. In our case I would prefer to maximise specificity as I personally think it more important that all non-spam messages make it into my inbox at the expense of the occasional spam message getting through the filter. These measures can be found easily using the `sklearn.metrics.classification_report()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99       967\n",
      "        spam       0.95      0.95      0.95       147\n",
      "\n",
      "    accuracy                           0.99      1114\n",
      "   macro avg       0.97      0.97      0.97      1114\n",
      "weighted avg       0.99      0.99      0.99      1114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_set['Labels'],test_set['predicted']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `f1-score` is the harmonic mean of precision and sensitivity.\n",
    "\n",
    "How might we make our model better? We could make our model more complex by making it sensitive to case and punctuation. Looking at the messages the were classified incorrectly, this seems like a good bet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>spam</td>\n",
       "      <td>Not heard from U4 a while. Call me now am here...</td>\n",
       "      <td>ham</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>spam</td>\n",
       "      <td>More people are dogging in your area now. Call...</td>\n",
       "      <td>ham</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>ham</td>\n",
       "      <td>Unlimited texts. Limited minutes.</td>\n",
       "      <td>spam</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>ham</td>\n",
       "      <td>26th OF JULY</td>\n",
       "      <td>spam</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nokia phone is lovly..</td>\n",
       "      <td>spam</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>ham</td>\n",
       "      <td>A Boy loved a gal. He propsd bt she didnt mind...</td>\n",
       "      <td>spam</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>ham</td>\n",
       "      <td>No calls..messages..missed calls</td>\n",
       "      <td>spam</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>ham</td>\n",
       "      <td>We have sent JD for Customer Service cum Accou...</td>\n",
       "      <td>spam</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>ham</td>\n",
       "      <td>Just taste fish curry :-P</td>\n",
       "      <td>spam</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>spam</td>\n",
       "      <td>Oh my god! I've found your number again! I'm s...</td>\n",
       "      <td>ham</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hi babe its Chloe, how r u? I was smashed on s...</td>\n",
       "      <td>ham</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>spam</td>\n",
       "      <td>0A$NETWORKS allow companies to bill for SMS, s...</td>\n",
       "      <td>ham</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>spam</td>\n",
       "      <td>RCT' THNQ Adrian for U text. Rgds Vatian</td>\n",
       "      <td>ham</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>spam</td>\n",
       "      <td>2/2 146tf150p</td>\n",
       "      <td>ham</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hello. We need some posh birds and chaps to us...</td>\n",
       "      <td>ham</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Labels                                                SMS predicted  \\\n",
       "114   spam  Not heard from U4 a while. Call me now am here...       ham   \n",
       "135   spam  More people are dogging in your area now. Call...       ham   \n",
       "152    ham                  Unlimited texts. Limited minutes.      spam   \n",
       "159    ham                                       26th OF JULY      spam   \n",
       "284    ham                             Nokia phone is lovly..      spam   \n",
       "293    ham  A Boy loved a gal. He propsd bt she didnt mind...      spam   \n",
       "302    ham                   No calls..messages..missed calls      spam   \n",
       "319    ham  We have sent JD for Customer Service cum Accou...      spam   \n",
       "331    ham                          Just taste fish curry :-P      spam   \n",
       "504   spam  Oh my god! I've found your number again! I'm s...       ham   \n",
       "546   spam  Hi babe its Chloe, how r u? I was smashed on s...       ham   \n",
       "741   spam  0A$NETWORKS allow companies to bill for SMS, s...       ham   \n",
       "876   spam           RCT' THNQ Adrian for U text. Rgds Vatian       ham   \n",
       "885   spam                                      2/2 146tf150p       ham   \n",
       "953   spam  Hello. We need some posh birds and chaps to us...       ham   \n",
       "\n",
       "     correct  \n",
       "114    False  \n",
       "135    False  \n",
       "152    False  \n",
       "159    False  \n",
       "284    False  \n",
       "293    False  \n",
       "302    False  \n",
       "319    False  \n",
       "331    False  \n",
       "504    False  \n",
       "546    False  \n",
       "741    False  \n",
       "876    False  \n",
       "885    False  \n",
       "953    False  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[test_set['correct']==False]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
